{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "gpu_device_name = tf.test.gpu_device_name()\n",
        "if gpu_device_name:\n",
        "    print(\"GPU device name:\", gpu_device_name)\n",
        "else:\n",
        "    print(\"No GPU found\")"
      ],
      "metadata": {
        "id": "WI_roboxGbrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30eb0d62-b6dd-44e6-a3a4-2ed679cb9b0d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "GPU device name: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper Methods\n",
        "import pickle\n",
        "from os.path import isfile, isdir\n",
        "\n",
        "def load_data(file_list):\n",
        "    for file in file_list:\n",
        "        features, labels = pickle.load(open(file, 'rb'))\n",
        "        for img, label in zip(features, labels):\n",
        "            yield img, label\n",
        "\n",
        "def preprocess(img, label):\n",
        "    img = tf.image.resize(img, (224, 224))\n",
        "    return img, label\n",
        "\n",
        "from urllib.request import urlretrieve\n",
        "from os.path import isfile, isdir\n",
        "\n",
        "from tqdm import tqdm\n",
        "import tarfile\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "class DownloadProgress(tqdm):\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num\n",
        "\n",
        "def download(dataset_folder_path):\n",
        "    if not isfile('cifar-10-python.tar.gz'):\n",
        "        with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
        "            urlretrieve(\n",
        "                'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
        "                'cifar-10-python.tar.gz',\n",
        "                pbar.hook)\n",
        "    else:\n",
        "        print('cifar-10-python.tar.gz already exists')\n",
        "\n",
        "    if not isdir(dataset_folder_path):\n",
        "        with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
        "            tar.extractall()\n",
        "            tar.close()\n",
        "    else:\n",
        "        print('cifar10 dataset already exists')\n",
        "\n",
        "def load_cifar10_batch(dataset_folder_path, batch_id):\n",
        "    with open(dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
        "        # note the encoding type is 'latin1'\n",
        "        batch = pickle.load(file, encoding='latin1')\n",
        "\n",
        "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    labels = batch['labels']\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "def one_hot_encode(x):\n",
        "    encoded = np.zeros((len(x), 10))\n",
        "\n",
        "    for idx, val in enumerate(x):\n",
        "        encoded[idx][val] = 1\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def _preprocess_and_save(one_hot_encode, features, labels, filename):\n",
        "    labels = one_hot_encode(labels)\n",
        "\n",
        "    pickle.dump((features, labels), open(filename, 'wb'))\n",
        "\n",
        "\n",
        "def preprocess_and_save_data(dataset_folder_path):\n",
        "    n_batches = 5\n",
        "    valid_features = []\n",
        "    valid_labels = []\n",
        "\n",
        "    for batch_i in range(1, n_batches + 1):\n",
        "        features, labels = load_cifar10_batch(dataset_folder_path, batch_i)\n",
        "\n",
        "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
        "        index_of_validation = int(len(features) * 0.1)\n",
        "\n",
        "        # preprocess the 90% of the whole dataset of the batch\n",
        "        # - normalize the features\n",
        "        # - one_hot_encode the lables\n",
        "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
        "        # - each file for each batch\n",
        "        _preprocess_and_save(one_hot_encode,\n",
        "                             features[:-index_of_validation], labels[:-index_of_validation],\n",
        "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
        "\n",
        "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
        "        # - take 10% of the whold dataset of the batch\n",
        "        # - add them into a list of\n",
        "        #   - valid_features\n",
        "        #   - valid_labels\n",
        "        valid_features.extend(features[-index_of_validation:])\n",
        "        valid_labels.extend(labels[-index_of_validation:])\n",
        "\n",
        "    # preprocess the all stacked validation dataset\n",
        "    _preprocess_and_save(one_hot_encode,\n",
        "                         np.array(valid_features), np.array(valid_labels),\n",
        "                         'preprocess_validation.p')\n",
        "\n",
        "    # load the test dataset\n",
        "    with open(dataset_folder_path + '/test_batch', mode='rb') as file:\n",
        "        batch = pickle.load(file, encoding='latin1')\n",
        "\n",
        "    # preprocess the testing data\n",
        "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    test_labels = batch['labels']\n",
        "\n",
        "    # Preprocess and Save all testing data\n",
        "    _preprocess_and_save(one_hot_encode,\n",
        "                         np.array(test_features), np.array(test_labels),\n",
        "                         'preprocess_testing.p')"
      ],
      "metadata": {
        "id": "8xeVFYPeYK0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "class AlexNet(tf.keras.Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        weight_decay = 5e-4\n",
        "\n",
        "        self.model = models.Sequential([\n",
        "            # Layer 1\n",
        "            layers.Input(shape=(224, 224, 3)),\n",
        "            layers.Conv2D(96, kernel_size=11, strides=4, activation='relu', padding='same',\n",
        "                          kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D(pool_size=3, strides=2),\n",
        "\n",
        "            # Layer 2\n",
        "            layers.Conv2D(256, kernel_size=5, padding='same', activation='relu',\n",
        "                          kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "            layers.BatchNormalization(),\n",
        "            layers.MaxPooling2D(pool_size=3, strides=2),\n",
        "\n",
        "            # Layer 3–5\n",
        "            layers.Conv2D(384, kernel_size=3, padding='same', activation='relu',\n",
        "                          kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "            layers.Conv2D(384, kernel_size=3, padding='same', activation='relu',\n",
        "                          kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "            layers.Conv2D(256, kernel_size=3, padding='same', activation='relu',\n",
        "                          kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "            layers.MaxPooling2D(pool_size=3, strides=2),\n",
        "\n",
        "            # Flatten\n",
        "            layers.Flatten(),\n",
        "\n",
        "            # FC layers\n",
        "            layers.Dense(4096, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(4096, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "            layers.Dropout(0.5),\n",
        "\n",
        "            # Output\n",
        "            layers.Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(weight_decay))\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.model(inputs)\n",
        "\n",
        "def train(model, train_dataset, val_dataset, epochs, learning_rate, save_path):\n",
        "    with tf.device(gpu_device_name):\n",
        "      model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=[tf.keras.metrics.TopKCategoricalAccuracy(k=1),tf.keras.metrics.TopKCategoricalAccuracy(k=5)])\n",
        "\n",
        "      history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset, steps_per_epoch=800)\n",
        "    model.save(save_path)\n",
        "    return history"
      ],
      "metadata": {
        "id": "MxjOrTXjYLtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "dataset = 'cifar10'\n",
        "dataset_path = 'none'\n",
        "learning_rate = 0.00005\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "\n",
        "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
        "save_path = './image_classification.keras'\n",
        "\n",
        "if dataset == 'cifar10' and dataset_path == 'none':\n",
        "    download(cifar10_dataset_folder_path)\n",
        "\n",
        "if dataset == 'cifar10':\n",
        "    print('preprocess_and_save_data...')\n",
        "    preprocess_and_save_data(cifar10_dataset_folder_path)\n",
        "\n",
        "    print('load features and labels for valid dataset...')\n",
        "    valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))\n",
        "\n",
        "    print('converting valid images to fit into imagenet size...')\n",
        "    with tf.device(gpu_device_name):\n",
        "      tmp_valid_features = tf.image.resize(valid_features, (224,224))\n",
        "else:\n",
        "    sys.exit(0)\n",
        "\n",
        "with tf.device(gpu_device_name):\n",
        "  model = AlexNet(num_classes=10)\n",
        "\n",
        "  file_list = [f'preprocess_batch_{i}.p' for i in range(1, 6)]\n",
        "\n",
        "  dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: load_data(file_list),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(32, 32, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(num_classes,), dtype=tf.int64)\n",
        "    )\n",
        "  )\n",
        "\n",
        "  train_ds = (dataset\n",
        "            .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "            .shuffle(1000)\n",
        "            .batch(batch_size)\n",
        "            .repeat()\n",
        "            .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "  val_ds = tf.data.Dataset.from_tensor_slices((tmp_valid_features, valid_labels))\n",
        "  val_ds = (val_ds\n",
        "            .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "            .batch(batch_size)\n",
        "            .shuffle(1000)\n",
        "            .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "  history = train(model, train_ds, val_ds, epochs, learning_rate, save_path)"
      ],
      "metadata": {
        "id": "lBBfmzncYSAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cbf205e-a2ad-4dd5-d098-1681a0140c74",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10-python.tar.gz already exists\n",
            "cifar10 dataset already exists\n",
            "preprocess_and_save_data...\n",
            "load features and labels for valid dataset...\n",
            "converting valid images to fit into imagenet size...\n",
            "Epoch 1/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 108ms/step - loss: 7.1936 - top_k_categorical_accuracy: 0.3983 - top_k_categorical_accuracy_1: 0.8472 - val_loss: 5.0446 - val_top_k_categorical_accuracy: 0.6228 - val_top_k_categorical_accuracy_1: 0.9598\n",
            "Epoch 2/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 93ms/step - loss: 4.8471 - top_k_categorical_accuracy: 0.6416 - top_k_categorical_accuracy_1: 0.9661 - val_loss: 4.4257 - val_top_k_categorical_accuracy: 0.6724 - val_top_k_categorical_accuracy_1: 0.9744\n",
            "Epoch 3/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 94ms/step - loss: 4.1449 - top_k_categorical_accuracy: 0.7295 - top_k_categorical_accuracy_1: 0.9807 - val_loss: 3.9146 - val_top_k_categorical_accuracy: 0.7234 - val_top_k_categorical_accuracy_1: 0.9782\n",
            "Epoch 4/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 94ms/step - loss: 3.5722 - top_k_categorical_accuracy: 0.8037 - top_k_categorical_accuracy_1: 0.9906 - val_loss: 3.5453 - val_top_k_categorical_accuracy: 0.7482 - val_top_k_categorical_accuracy_1: 0.9848\n",
            "Epoch 5/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 94ms/step - loss: 3.0886 - top_k_categorical_accuracy: 0.8633 - top_k_categorical_accuracy_1: 0.9958 - val_loss: 3.4810 - val_top_k_categorical_accuracy: 0.7242 - val_top_k_categorical_accuracy_1: 0.9738\n",
            "Epoch 6/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 97ms/step - loss: 2.6850 - top_k_categorical_accuracy: 0.9126 - top_k_categorical_accuracy_1: 0.9990 - val_loss: 3.1256 - val_top_k_categorical_accuracy: 0.7690 - val_top_k_categorical_accuracy_1: 0.9834\n",
            "Epoch 7/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 93ms/step - loss: 2.3588 - top_k_categorical_accuracy: 0.9444 - top_k_categorical_accuracy_1: 0.9999 - val_loss: 3.0157 - val_top_k_categorical_accuracy: 0.7612 - val_top_k_categorical_accuracy_1: 0.9834\n",
            "Epoch 8/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 94ms/step - loss: 2.0861 - top_k_categorical_accuracy: 0.9614 - top_k_categorical_accuracy_1: 0.9998 - val_loss: 2.7952 - val_top_k_categorical_accuracy: 0.7598 - val_top_k_categorical_accuracy_1: 0.9780\n",
            "Epoch 9/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 93ms/step - loss: 1.8745 - top_k_categorical_accuracy: 0.9621 - top_k_categorical_accuracy_1: 0.9999 - val_loss: 2.7202 - val_top_k_categorical_accuracy: 0.7502 - val_top_k_categorical_accuracy_1: 0.9838\n",
            "Epoch 10/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 94ms/step - loss: 1.6606 - top_k_categorical_accuracy: 0.9699 - top_k_categorical_accuracy_1: 1.0000 - val_loss: 2.4602 - val_top_k_categorical_accuracy: 0.7622 - val_top_k_categorical_accuracy_1: 0.9748\n",
            "Epoch 11/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 96ms/step - loss: 1.4780 - top_k_categorical_accuracy: 0.9750 - top_k_categorical_accuracy_1: 1.0000 - val_loss: 2.4876 - val_top_k_categorical_accuracy: 0.7556 - val_top_k_categorical_accuracy_1: 0.9780\n",
            "Epoch 12/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 96ms/step - loss: 1.3261 - top_k_categorical_accuracy: 0.9745 - top_k_categorical_accuracy_1: 1.0000 - val_loss: 2.2854 - val_top_k_categorical_accuracy: 0.7778 - val_top_k_categorical_accuracy_1: 0.9832\n",
            "Epoch 13/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 94ms/step - loss: 1.1921 - top_k_categorical_accuracy: 0.9767 - top_k_categorical_accuracy_1: 1.0000 - val_loss: 2.0991 - val_top_k_categorical_accuracy: 0.7768 - val_top_k_categorical_accuracy_1: 0.9804\n",
            "Epoch 14/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 97ms/step - loss: 1.0679 - top_k_categorical_accuracy: 0.9808 - top_k_categorical_accuracy_1: 1.0000 - val_loss: 2.0489 - val_top_k_categorical_accuracy: 0.7710 - val_top_k_categorical_accuracy_1: 0.9788\n",
            "Epoch 15/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 94ms/step - loss: 0.9690 - top_k_categorical_accuracy: 0.9831 - top_k_categorical_accuracy_1: 1.0000 - val_loss: 2.1020 - val_top_k_categorical_accuracy: 0.7630 - val_top_k_categorical_accuracy_1: 0.9802\n",
            "Epoch 16/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 98ms/step - loss: 0.9004 - top_k_categorical_accuracy: 0.9801 - top_k_categorical_accuracy_1: 1.0000 - val_loss: 1.9310 - val_top_k_categorical_accuracy: 0.7722 - val_top_k_categorical_accuracy_1: 0.9798\n",
            "Epoch 17/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 94ms/step - loss: 0.8175 - top_k_categorical_accuracy: 0.9855 - top_k_categorical_accuracy_1: 0.9999 - val_loss: 1.9820 - val_top_k_categorical_accuracy: 0.7628 - val_top_k_categorical_accuracy_1: 0.9756\n",
            "Epoch 18/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 94ms/step - loss: 0.7719 - top_k_categorical_accuracy: 0.9815 - top_k_categorical_accuracy_1: 1.0000 - val_loss: 1.8384 - val_top_k_categorical_accuracy: 0.7698 - val_top_k_categorical_accuracy_1: 0.9798\n",
            "Epoch 19/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 96ms/step - loss: 0.7306 - top_k_categorical_accuracy: 0.9809 - top_k_categorical_accuracy_1: 0.9999 - val_loss: 1.7431 - val_top_k_categorical_accuracy: 0.7680 - val_top_k_categorical_accuracy_1: 0.9768\n",
            "Epoch 20/20\n",
            "\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 93ms/step - loss: 0.6677 - top_k_categorical_accuracy: 0.9881 - top_k_categorical_accuracy_1: 1.0000 - val_loss: 1.8305 - val_top_k_categorical_accuracy: 0.7552 - val_top_k_categorical_accuracy_1: 0.9806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(history):\n",
        "  history = history.history\n",
        "  loss_values = history['loss']\n",
        "  val_loss_values = history['val_loss']\n",
        "  top1 = history['top_k_categorical_accuracy']\n",
        "  val_top1 = history['val_top_k_categorical_accuracy']\n",
        "  top5 = history['top_k_categorical_accuracy_1']\n",
        "  val_top5 = history['val_top_k_categorical_accuracy_1']\n",
        "  epochs_range = range(1, len(loss_values) + 1)\n",
        "\n",
        "  # plotting loss\n",
        "  plt.figure(figsize=(16,8))\n",
        "  plt.subplot(1, 3, 1)\n",
        "  plt.plot(epochs_range, loss_values, label = 'train loss')\n",
        "  plt.plot(epochs_range, val_loss_values, label = 'validation loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  # plotting top 1 accuracy\n",
        "  plt.subplot(1, 3, 2)\n",
        "  plt.plot(epochs_range, top1, label='Train Top-1 Acc')\n",
        "  plt.plot(epochs_range, val_top1, label='Val Top-1 Acc')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title('Top-1 Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  # plotting top 5 accuracy\n",
        "  plt.subplot(1, 3, 3)\n",
        "  plt.plot(epochs_range, top5, label='Train Top-5 Acc')\n",
        "  plt.plot(epochs_range, val_top5, label='Val Top-5 Acc')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title('Top-5 Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# print(history.history.keys())\n",
        "\n",
        "plot_training_history(history)\n"
      ],
      "metadata": {
        "id": "p-RVPk231zfP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}